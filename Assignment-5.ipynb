{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building cnn from scratch without using transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train=loadlocal_mnist(images_path='train-images-idx3-ubyte',labels_path='train-labels-idx1-ubyte')\n",
    "X_test,Y_test=loadlocal_mnist(images_path='t10k-images-idx3-ubyte',labels_path='t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(X_train[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.eye(10)[Y_train.astype('int32')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.eye(10)[Y_test.astype('int32')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-8362a9fb3a3c>:8: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    }
   ],
   "source": [
    "# Placeholder variable for the input images\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28*28], name='X')\n",
    "# Reshape it into [num_images, img_height, img_width, num_channels]\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# Placeholder variable for the true labels associated with the images\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input, num_input_channels, filter_size, num_filters, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # Shape of the filter-weights for the convolution\n",
    "        shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "        # Create new weights (filters) with the given shape\n",
    "        weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "        # Create new biases, one for each filter\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_filters]))\n",
    "\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.conv2d(input=input, filter=weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "        # Add the biases to the results of the convolution.\n",
    "        layer += biases\n",
    "        \n",
    "        return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_pool_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.max_pool(value=input, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_relu_layer(input, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "        # TensorFlow operation for convolution\n",
    "        layer = tf.nn.relu(input)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input, num_inputs, num_outputs, name):\n",
    "    \n",
    "    with tf.variable_scope(name) as scope:\n",
    "\n",
    "        # Create new weights and biases.\n",
    "        weights = tf.Variable(tf.truncated_normal([num_inputs, num_outputs], stddev=0.05))\n",
    "        biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "        \n",
    "        # Multiply the input and weights, and then add the bias-values.\n",
    "        layer = tf.matmul(input, weights) + biases\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/samila/tensorflow_env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Layer 1\n",
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image, num_input_channels=1, filter_size=5, num_filters=6, name =\"conv1\")\n",
    "\n",
    "# Pooling Layer 1\n",
    "layer_pool1 = new_pool_layer(layer_conv1, name=\"pool1\")\n",
    "\n",
    "# RelU layer 1\n",
    "layer_relu1 = new_relu_layer(layer_pool1, name=\"relu1\")\n",
    "\n",
    "# Convolutional Layer 2\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input=layer_relu1, num_input_channels=6, filter_size=5, num_filters=16, name= \"conv2\")\n",
    "\n",
    "# Pooling Layer 2\n",
    "layer_pool2 = new_pool_layer(layer_conv2, name=\"pool2\")\n",
    "\n",
    "# RelU layer 2\n",
    "layer_relu2 = new_relu_layer(layer_pool2, name=\"relu2\")\n",
    "\n",
    "# Flatten Layer\n",
    "num_features = layer_relu2.get_shape()[1:4].num_elements()\n",
    "layer_flat = tf.reshape(layer_relu2, [-1, num_features])\n",
    "\n",
    "# Fully-Connected Layer 1\n",
    "layer_fc1 = new_fc_layer(layer_flat, num_inputs=num_features, num_outputs=128, name=\"fc1\")\n",
    "\n",
    "# RelU layer 3\n",
    "layer_relu3 = new_relu_layer(layer_fc1, name=\"relu3\")\n",
    "\n",
    "# Fully-Connected Layer 2\n",
    "layer_fc2 = new_fc_layer(input=layer_relu3, num_inputs=128, num_outputs=10, name=\"fc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Use Softmax function to normalize the output\n",
    "with tf.variable_scope(\"Softmax\"):\n",
    "    y_pred = tf.nn.softmax(layer_fc2)\n",
    "    y_pred_cls = tf.argmax(y_pred, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-0fd2322922db>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Cross entropy cost function\n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
    "    cost = tf.reduce_mean(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Adam Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 200 \n",
    "learning_rate = 0.001 \n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 0.716035, Training Accuracy= 0.72656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73210\n",
      "Iter 1, Loss= 0.573506, Training Accuracy= 0.76562\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.77230\n",
      "Iter 2, Loss= 0.475227, Training Accuracy= 0.77344\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.79790\n",
      "Iter 3, Loss= 0.420315, Training Accuracy= 0.79688\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.81370\n",
      "Iter 4, Loss= 0.383841, Training Accuracy= 0.81250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.82600\n",
      "Iter 5, Loss= 0.357911, Training Accuracy= 0.82812\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.83330\n",
      "Iter 6, Loss= 0.340631, Training Accuracy= 0.83594\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.83920\n",
      "Iter 7, Loss= 0.326186, Training Accuracy= 0.85938\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.84270\n",
      "Iter 8, Loss= 0.314003, Training Accuracy= 0.86719\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.84690\n",
      "Iter 9, Loss= 0.304556, Training Accuracy= 0.87500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.85040\n",
      "Iter 10, Loss= 0.295963, Training Accuracy= 0.87500\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.85350\n",
      "Iter 11, Loss= 0.287025, Training Accuracy= 0.89844\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.85620\n",
      "Iter 12, Loss= 0.280258, Training Accuracy= 0.89844\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.85820\n",
      "Iter 13, Loss= 0.273414, Training Accuracy= 0.89844\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.85980\n",
      "Iter 14, Loss= 0.265850, Training Accuracy= 0.89844\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.86240\n",
      "Iter 15, Loss= 0.258517, Training Accuracy= 0.89844\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.86400\n",
      "Iter 16, Loss= 0.251465, Training Accuracy= 0.90625\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.86560\n",
      "Iter 17, Loss= 0.245687, Training Accuracy= 0.91406\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.86600\n",
      "Iter 18, Loss= 0.239628, Training Accuracy= 0.91406\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.86660\n",
      "Iter 19, Loss= 0.233994, Training Accuracy= 0.92188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.86750\n",
      "Iter 20, Loss= 0.228898, Training Accuracy= 0.92188\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87000\n",
      "Iter 21, Loss= 0.224129, Training Accuracy= 0.92969\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87100\n",
      "Iter 22, Loss= 0.219858, Training Accuracy= 0.92969\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87250\n",
      "Iter 23, Loss= 0.215590, Training Accuracy= 0.92969\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87450\n",
      "Iter 24, Loss= 0.211056, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87570\n",
      "Iter 25, Loss= 0.206609, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87580\n",
      "Iter 26, Loss= 0.202433, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87730\n",
      "Iter 27, Loss= 0.198758, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87790\n",
      "Iter 28, Loss= 0.194460, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87790\n",
      "Iter 29, Loss= 0.190199, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87880\n",
      "Iter 30, Loss= 0.186463, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.87940\n",
      "Iter 31, Loss= 0.182777, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88030\n",
      "Iter 32, Loss= 0.179112, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88090\n",
      "Iter 33, Loss= 0.175707, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88170\n",
      "Iter 34, Loss= 0.172428, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88180\n",
      "Iter 35, Loss= 0.169822, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88220\n",
      "Iter 36, Loss= 0.166645, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88250\n",
      "Iter 37, Loss= 0.163457, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88320\n",
      "Iter 38, Loss= 0.160737, Training Accuracy= 0.93750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88470\n",
      "Iter 39, Loss= 0.157206, Training Accuracy= 0.94531\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88480\n",
      "Iter 40, Loss= 0.154466, Training Accuracy= 0.94531\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88520\n",
      "Iter 41, Loss= 0.151406, Training Accuracy= 0.94531\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88560\n",
      "Iter 42, Loss= 0.148778, Training Accuracy= 0.95312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88660\n",
      "Iter 43, Loss= 0.145829, Training Accuracy= 0.95312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88760\n",
      "Iter 44, Loss= 0.143165, Training Accuracy= 0.95312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88830\n",
      "Iter 45, Loss= 0.140197, Training Accuracy= 0.96094\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88930\n",
      "Iter 46, Loss= 0.138122, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.88970\n",
      "Iter 47, Loss= 0.135373, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89050\n",
      "Iter 48, Loss= 0.133335, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89010\n",
      "Iter 49, Loss= 0.130826, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89060\n",
      "Iter 50, Loss= 0.129190, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89170\n",
      "Iter 51, Loss= 0.127687, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89200\n",
      "Iter 52, Loss= 0.126021, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89280\n",
      "Iter 53, Loss= 0.124144, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89310\n",
      "Iter 54, Loss= 0.123129, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89290\n",
      "Iter 55, Loss= 0.121670, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89370\n",
      "Iter 56, Loss= 0.121096, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89330\n",
      "Iter 57, Loss= 0.119516, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89330\n",
      "Iter 58, Loss= 0.118148, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89400\n",
      "Iter 59, Loss= 0.117084, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89390\n",
      "Iter 60, Loss= 0.115772, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89490\n",
      "Iter 61, Loss= 0.113959, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89480\n",
      "Iter 62, Loss= 0.112249, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89570\n",
      "Iter 63, Loss= 0.111699, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89590\n",
      "Iter 64, Loss= 0.110097, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89610\n",
      "Iter 65, Loss= 0.109894, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89670\n",
      "Iter 66, Loss= 0.109081, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89680\n",
      "Iter 67, Loss= 0.107777, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89660\n",
      "Iter 68, Loss= 0.107238, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89680\n",
      "Iter 69, Loss= 0.106373, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89640\n",
      "Iter 70, Loss= 0.105745, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89640\n",
      "Iter 71, Loss= 0.105056, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89720\n",
      "Iter 72, Loss= 0.103844, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89700\n",
      "Iter 73, Loss= 0.103190, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89720\n",
      "Iter 74, Loss= 0.101770, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89730\n",
      "Iter 75, Loss= 0.101270, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89700\n",
      "Iter 76, Loss= 0.100359, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89770\n",
      "Iter 77, Loss= 0.099338, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89800\n",
      "Iter 78, Loss= 0.098430, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89850\n",
      "Iter 79, Loss= 0.097871, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89850\n",
      "Iter 80, Loss= 0.097092, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89930\n",
      "Iter 81, Loss= 0.096106, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.89910\n",
      "Iter 82, Loss= 0.095653, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89940\n",
      "Iter 83, Loss= 0.095186, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.89980\n",
      "Iter 84, Loss= 0.094342, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90100\n",
      "Iter 85, Loss= 0.093214, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90150\n",
      "Iter 86, Loss= 0.092575, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90140\n",
      "Iter 87, Loss= 0.092086, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90200\n",
      "Iter 88, Loss= 0.091259, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90210\n",
      "Iter 89, Loss= 0.091012, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90190\n",
      "Iter 90, Loss= 0.089561, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90200\n",
      "Iter 91, Loss= 0.088737, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90170\n",
      "Iter 92, Loss= 0.088054, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90220\n",
      "Iter 93, Loss= 0.087065, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90250\n",
      "Iter 94, Loss= 0.086303, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90300\n",
      "Iter 95, Loss= 0.086187, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90300\n",
      "Iter 96, Loss= 0.084699, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90350\n",
      "Iter 97, Loss= 0.085143, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90320\n",
      "Iter 98, Loss= 0.083328, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90360\n",
      "Iter 99, Loss= 0.083028, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90330\n",
      "Iter 100, Loss= 0.082761, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90390\n",
      "Iter 101, Loss= 0.081724, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90410\n",
      "Iter 102, Loss= 0.080858, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90370\n",
      "Iter 103, Loss= 0.080618, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90390\n",
      "Iter 104, Loss= 0.079566, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90360\n",
      "Iter 105, Loss= 0.078512, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90450\n",
      "Iter 106, Loss= 0.077951, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90430\n",
      "Iter 107, Loss= 0.077551, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90420\n",
      "Iter 108, Loss= 0.077629, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90450\n",
      "Iter 109, Loss= 0.076891, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90450\n",
      "Iter 110, Loss= 0.076591, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90440\n",
      "Iter 111, Loss= 0.075307, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90440\n",
      "Iter 112, Loss= 0.075751, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90500\n",
      "Iter 113, Loss= 0.075302, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90510\n",
      "Iter 114, Loss= 0.074803, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90550\n",
      "Iter 115, Loss= 0.074262, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90570\n",
      "Iter 116, Loss= 0.074660, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90590\n",
      "Iter 117, Loss= 0.073244, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90610\n",
      "Iter 118, Loss= 0.072887, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90660\n",
      "Iter 119, Loss= 0.072842, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90620\n",
      "Iter 120, Loss= 0.072366, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90640\n",
      "Iter 121, Loss= 0.072471, Training Accuracy= 0.97656\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90670\n",
      "Iter 122, Loss= 0.071368, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90680\n",
      "Iter 123, Loss= 0.070943, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90660\n",
      "Iter 124, Loss= 0.070086, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90680\n",
      "Iter 125, Loss= 0.070179, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90670\n",
      "Iter 126, Loss= 0.069678, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90660\n",
      "Iter 127, Loss= 0.069628, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90660\n",
      "Iter 128, Loss= 0.068986, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90740\n",
      "Iter 129, Loss= 0.068565, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90750\n",
      "Iter 130, Loss= 0.068971, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 131, Loss= 0.068591, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90710\n",
      "Iter 132, Loss= 0.067755, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90700\n",
      "Iter 133, Loss= 0.067660, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90670\n",
      "Iter 134, Loss= 0.067290, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90610\n",
      "Iter 135, Loss= 0.067485, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90670\n",
      "Iter 136, Loss= 0.066878, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90670\n",
      "Iter 137, Loss= 0.066075, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90740\n",
      "Iter 138, Loss= 0.066444, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 139, Loss= 0.065619, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90710\n",
      "Iter 140, Loss= 0.065380, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90700\n",
      "Iter 141, Loss= 0.065832, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 142, Loss= 0.065126, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90740\n",
      "Iter 143, Loss= 0.064691, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90770\n",
      "Iter 144, Loss= 0.064745, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90770\n",
      "Iter 145, Loss= 0.064656, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90810\n",
      "Iter 146, Loss= 0.064178, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90780\n",
      "Iter 147, Loss= 0.063786, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90720\n",
      "Iter 148, Loss= 0.063312, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90790\n",
      "Iter 149, Loss= 0.063212, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90720\n",
      "Iter 150, Loss= 0.062734, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 151, Loss= 0.062592, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90710\n",
      "Iter 152, Loss= 0.062709, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90750\n",
      "Iter 153, Loss= 0.062268, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90770\n",
      "Iter 154, Loss= 0.062722, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 155, Loss= 0.061695, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90740\n",
      "Iter 156, Loss= 0.061620, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90760\n",
      "Iter 157, Loss= 0.061257, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90790\n",
      "Iter 158, Loss= 0.061130, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90750\n",
      "Iter 159, Loss= 0.061541, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90710\n",
      "Iter 160, Loss= 0.060841, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90750\n",
      "Iter 161, Loss= 0.060236, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 162, Loss= 0.061402, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.90720\n",
      "Iter 163, Loss= 0.060911, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90760\n",
      "Iter 164, Loss= 0.060556, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90760\n",
      "Iter 165, Loss= 0.059722, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90770\n",
      "Iter 166, Loss= 0.060198, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90790\n",
      "Iter 167, Loss= 0.059475, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90760\n",
      "Iter 168, Loss= 0.059544, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90790\n",
      "Iter 169, Loss= 0.059002, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90770\n",
      "Iter 170, Loss= 0.058931, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90780\n",
      "Iter 171, Loss= 0.058267, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90720\n",
      "Iter 172, Loss= 0.058295, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90720\n",
      "Iter 173, Loss= 0.058210, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90700\n",
      "Iter 174, Loss= 0.057455, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 175, Loss= 0.056775, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90750\n",
      "Iter 176, Loss= 0.057380, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 177, Loss= 0.056923, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90780\n",
      "Iter 178, Loss= 0.055977, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90770\n",
      "Iter 179, Loss= 0.056428, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90780\n",
      "Iter 180, Loss= 0.055740, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90810\n",
      "Iter 181, Loss= 0.054907, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90800\n",
      "Iter 182, Loss= 0.055275, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90800\n",
      "Iter 183, Loss= 0.054433, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90800\n",
      "Iter 184, Loss= 0.054183, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90800\n",
      "Iter 185, Loss= 0.054544, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90810\n",
      "Iter 186, Loss= 0.053623, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90840\n",
      "Iter 187, Loss= 0.054281, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90810\n",
      "Iter 188, Loss= 0.053888, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90810\n",
      "Iter 189, Loss= 0.053378, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90790\n",
      "Iter 190, Loss= 0.053595, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90760\n",
      "Iter 191, Loss= 0.052683, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90770\n",
      "Iter 192, Loss= 0.052834, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90770\n",
      "Iter 193, Loss= 0.052040, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90740\n",
      "Iter 194, Loss= 0.051697, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 195, Loss= 0.051957, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 196, Loss= 0.052007, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 197, Loss= 0.052101, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 198, Loss= 0.050868, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90730\n",
      "Iter 199, Loss= 0.051482, Training Accuracy= 0.98438\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.90710\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    for i in range(training_iters):\n",
    "        for batch in range(len(X_train)//batch_size):\n",
    "            batch_x = X_train[batch*batch_size:min((batch+1)*batch_size,len(X_train))]\n",
    "            batch_y = Y_train[batch*batch_size:min((batch+1)*batch_size,len(Y_train))]\n",
    "            opt = sess.run(optimizer, feed_dict={x: batch_x,y_true: batch_y})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y_true: batch_y})\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calculate accuracy for all 10000 mnist test images\n",
    "        test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: X_test,y_true : Y_test})\n",
    "        train_loss.append(loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
